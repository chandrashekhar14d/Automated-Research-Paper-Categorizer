{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26de8ea",
   "metadata": {
    "id": "Op9b0WdNy3uZ",
    "outputId": "8d6c1424-701c-48d3-b777-0ed575106de0",
    "papermill": {
     "duration": 0.011477,
     "end_time": "2024-02-09T21:26:12.019093",
     "exception": false,
     "start_time": "2024-02-09T21:26:12.007616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73313fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:26:12.041009Z",
     "iopub.status.busy": "2024-02-09T21:26:12.040494Z",
     "iopub.status.idle": "2024-02-09T21:26:30.608788Z",
     "shell.execute_reply": "2024-02-09T21:26:30.607800Z"
    },
    "id": "4vLrBjS9FCIb",
    "papermill": {
     "duration": 18.582676,
     "end_time": "2024-02-09T21:26:30.611722",
     "exception": false,
     "start_time": "2024-02-09T21:26:12.029046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 21:26:16.416420: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-09 21:26:16.416549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-09 21:26:16.561489: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU,SimpleRNN\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "# from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55be1499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:26:30.634873Z",
     "iopub.status.busy": "2024-02-09T21:26:30.633723Z",
     "iopub.status.idle": "2024-02-09T21:26:32.126983Z",
     "shell.execute_reply": "2024-02-09T21:26:32.125345Z"
    },
    "id": "LsmKDTYqwIBl",
    "papermill": {
     "duration": 1.507846,
     "end_time": "2024-02-09T21:26:32.129992",
     "exception": false,
     "start_time": "2024-02-09T21:26:30.622146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('/kaggle/input/kriti2024/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee890ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:26:32.156079Z",
     "iopub.status.busy": "2024-02-09T21:26:32.155439Z",
     "iopub.status.idle": "2024-02-09T21:26:32.260017Z",
     "shell.execute_reply": "2024-02-09T21:26:32.258849Z"
    },
    "id": "Tabx0o-j4M2f",
    "outputId": "d80d65ba-450c-4aea-ec34-c6f704bd2799",
    "papermill": {
     "duration": 0.120702,
     "end_time": "2024-02-09T21:26:32.262782",
     "exception": false,
     "start_time": "2024-02-09T21:26:32.142080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>CONTEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cs.LO']</td>\n",
       "      <td>Axiomatic Aspects of Default Inference. This p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['math.GR']</td>\n",
       "      <td>On extensions of group with infinite conjugacy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']</td>\n",
       "      <td>An Analysis of Complex-Valued CNNs for RF Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['math.PR', 'math.ST', 'stat.TH']</td>\n",
       "      <td>On the reconstruction of the drift of a diffus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cs.IT', 'math.IT']</td>\n",
       "      <td>Three classes of propagation rules for GRS and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51205</th>\n",
       "      <td>['math.AP']</td>\n",
       "      <td>Generalized Fourier Integral Operators on spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51206</th>\n",
       "      <td>['cs.CV', 'cs.CL']</td>\n",
       "      <td>Weakly-Supervised 3D Visual Grounding based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51207</th>\n",
       "      <td>['math.CV']</td>\n",
       "      <td>Strongly pseudoconvex handlebodies. We give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51208</th>\n",
       "      <td>['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']</td>\n",
       "      <td>Improving End-to-End Speech Processing by Effi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51209</th>\n",
       "      <td>['math.PR']</td>\n",
       "      <td>Second class particles as microscopic characte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51210 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Categories  \\\n",
       "0                                     ['cs.LO']   \n",
       "1                                   ['math.GR']   \n",
       "2      ['cs.LG', 'cs.IT', 'eess.SP', 'math.IT']   \n",
       "3             ['math.PR', 'math.ST', 'stat.TH']   \n",
       "4                          ['cs.IT', 'math.IT']   \n",
       "...                                         ...   \n",
       "51205                               ['math.AP']   \n",
       "51206                        ['cs.CV', 'cs.CL']   \n",
       "51207                               ['math.CV']   \n",
       "51208    ['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']   \n",
       "51209                               ['math.PR']   \n",
       "\n",
       "                                                 CONTEXT  \n",
       "0      Axiomatic Aspects of Default Inference. This p...  \n",
       "1      On extensions of group with infinite conjugacy...  \n",
       "2      An Analysis of Complex-Valued CNNs for RF Data...  \n",
       "3      On the reconstruction of the drift of a diffus...  \n",
       "4      Three classes of propagation rules for GRS and...  \n",
       "...                                                  ...  \n",
       "51205  Generalized Fourier Integral Operators on spac...  \n",
       "51206  Weakly-Supervised 3D Visual Grounding based on...  \n",
       "51207  Strongly pseudoconvex handlebodies. We give an...  \n",
       "51208  Improving End-to-End Speech Processing by Effi...  \n",
       "51209  Second class particles as microscopic characte...  \n",
       "\n",
       "[51210 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['CONTEXT'] = train_df['Title'] + \". \" + train_df['Abstract']\n",
    "train_df.drop(labels=['Title', 'Abstract', 'Id'], axis=1, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528fb984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:26:32.285700Z",
     "iopub.status.busy": "2024-02-09T21:26:32.285265Z",
     "iopub.status.idle": "2024-02-09T21:26:32.290350Z",
     "shell.execute_reply": "2024-02-09T21:26:32.289162Z"
    },
    "id": "cxtsvH_fkv62",
    "papermill": {
     "duration": 0.019324,
     "end_time": "2024-02-09T21:26:32.292646",
     "exception": false,
     "start_time": "2024-02-09T21:26:32.273322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seqlen = 250\n",
    "batch_size = 256\n",
    "padding_token = \"<pad>\"\n",
    "auto = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a340a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:26:32.315273Z",
     "iopub.status.busy": "2024-02-09T21:26:32.314887Z",
     "iopub.status.idle": "2024-02-09T21:27:39.454190Z",
     "shell.execute_reply": "2024-02-09T21:27:39.452881Z"
    },
    "id": "rq64TcSwWGR2",
    "papermill": {
     "duration": 67.154341,
     "end_time": "2024-02-09T21:27:39.457469",
     "exception": false,
     "start_time": "2024-02-09T21:26:32.303128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def decontract(sentence):\n",
    "    # specific\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can\\'t\", \"can not\", sentence)\n",
    "\n",
    "    # general\n",
    "    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "    return sentence\n",
    "\n",
    "def cleanPunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', '', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\"\", sentence)\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stopwords) + \")\\\\W\", re.I)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "train_df['CONTEXT']=train_df['CONTEXT'].str.lower()\n",
    "train_df['CONTEXT']=train_df['CONTEXT'].apply(decontract)\n",
    "train_df['CONTEXT']=train_df['CONTEXT'].apply(cleanPunc)\n",
    "train_df['CONTEXT']=train_df['CONTEXT'].apply(removeStopWords)\n",
    "train_df['CONTEXT']=train_df['CONTEXT'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b7566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:27:39.482019Z",
     "iopub.status.busy": "2024-02-09T21:27:39.481584Z",
     "iopub.status.idle": "2024-02-09T21:27:39.487248Z",
     "shell.execute_reply": "2024-02-09T21:27:39.486126Z"
    },
    "id": "at3uiAAnSCSy",
    "outputId": "4960c1a6-4cff-4ddd-b3a4-dd7d734a6c5a",
    "papermill": {
     "duration": 0.021167,
     "end_time": "2024-02-09T21:27:39.489647",
     "exception": false,
     "start_time": "2024-02-09T21:27:39.468480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from collections import Counter\n",
    "\n",
    "\n",
    "# # Tokenize the sentences into words and create a list of all words\n",
    "# all_words = []\n",
    "# for sentence in train_df['CONTEXT']:\n",
    "#     words = word_tokenize(sentence)\n",
    "#     all_words.extend(words)\n",
    "\n",
    "# # Count the frequency of each word\n",
    "# word_freq = Counter(all_words)\n",
    "\n",
    "# # Get the top 10 words\n",
    "# top_10_words = word_freq.most_common(10)\n",
    "\n",
    "# # Convert the result to a DataFrame for easier display\n",
    "# top_10_words_df = pd.DataFrame(top_10_words, columns=['Word', 'Frequency'])\n",
    "\n",
    "# # Display the top 10 words and their frequencies\n",
    "# print(top_10_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630af1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:27:39.513708Z",
     "iopub.status.busy": "2024-02-09T21:27:39.513274Z",
     "iopub.status.idle": "2024-02-09T21:27:39.517790Z",
     "shell.execute_reply": "2024-02-09T21:27:39.516574Z"
    },
    "id": "OFO1caMCScwV",
    "papermill": {
     "duration": 0.018939,
     "end_time": "2024-02-09T21:27:39.520149",
     "exception": false,
     "start_time": "2024-02-09T21:27:39.501210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def remove_top_words(sentence):\n",
    "#     words = word_tokenize(sentence)\n",
    "#     words = [word for word in words if word not in top_10_words]\n",
    "#     return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f57ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:27:39.543429Z",
     "iopub.status.busy": "2024-02-09T21:27:39.542781Z",
     "iopub.status.idle": "2024-02-09T21:27:39.547234Z",
     "shell.execute_reply": "2024-02-09T21:27:39.546320Z"
    },
    "id": "PueXH751X397",
    "outputId": "43c2e712-84ec-4354-f267-473d72a23dc2",
    "papermill": {
     "duration": 0.018776,
     "end_time": "2024-02-09T21:27:39.549550",
     "exception": false,
     "start_time": "2024-02-09T21:27:39.530774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_df['CONTEXT']=train_df['CONTEXT'].apply(remove_top_words)\n",
    "# train_df['CONTEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1daf6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:27:39.573262Z",
     "iopub.status.busy": "2024-02-09T21:27:39.572596Z",
     "iopub.status.idle": "2024-02-09T21:28:02.610150Z",
     "shell.execute_reply": "2024-02-09T21:28:02.608768Z"
    },
    "id": "PMzTRUrCyIUC",
    "outputId": "3b1d4a3a-b078-433b-f0df-eeed889232f8",
    "papermill": {
     "duration": 23.052856,
     "end_time": "2024-02-09T21:28:02.613143",
     "exception": false,
     "start_time": "2024-02-09T21:27:39.560287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 40495\n",
      "Number of rows in validation set: 5062\n",
      "Number of rows in test set: 5062\n",
      "58\n",
      "Abstract: b'characterization modular units provide exact formula complex exponents modular product expansion modular units deduce characterization modular units terms growth exponents answering question w kohnen'\n",
      "Label(s): ['math.NT']\n",
      " \n",
      "Abstract: b'performance analysis publish subscribe systems desktop grid offers solutions overcome several challenges answer increasingly needs scientific computing technology consists mainly exploiting resources geographically dispersed treat complex applications needing big power calculation important storage capacity however resources number increases need scalability selforganisation dynamic reconfigurations decentralisation performance becomes essential since properties exhibited pp systems convergence grid computing pp computing seems natural context paper evaluates scalability performance pp tools discovering registering services three protocols used purpose bonjour avahi freepastry studied behaviour theses protocols related two criteria elapsed time registrations services needed time discover new services aim analyse results order choose best protocol use order create decentralised middleware desktop grid'\n",
      "Label(s): ['cs.DC']\n",
      " \n",
      "Abstract: b'graph monomial ideals natural infinite graph whose vertices monomial ideals polynomial ring definition involves grobner bases action algebraic torus present algorithms computing affine schemes representing edges graph study induced subgraphs multigraded hilbert schemes squarefree monomial ideals latter case edges correspond generalized bistellar flips'\n",
      "Label(s): ['math.AC']\n",
      " \n",
      "Abstract: b'catprobing metricbased approach interpret pretrained models programming language attend code structure code pretrained models codeptms recently demonstrated significant success code intelligence interpret models probing methods applied however methods fail consider inherent characteristics codes paper address problem propose novel probing method catprobing quantitatively interpret codeptms attend code structure first denoise input code sequences based token types predefined compilers filter tokens whose attention scores small define new metric catscore measure commonality tokenlevel attention scores generated codeptms pairwise distances corresponding ast nodes higher catscore stronger ability codeptms capture code structure conduct extensive experiments integrate catprobing representative codeptms different programming languages experimental results show effectiveness catprobing codeptm interpretation codes data publicly available https github com nchen codeattention'\n",
      "Label(s): ['cs.LG', 'cs.AI', 'cs.SE', 'cs.PL']\n",
      " \n",
      "Abstract: b'deciphering visual pathways spectral clustering layerdistributed neural representations present approach analyzing grouping information contained within neural network activations permitting extraction spatial layout semantic segmentation behavior large pretrained vision models unlike prior work method conducts wholistic analysis network activation state leveraging features layers obviating need guess part model contains relevant information motivated classic spectral clustering formulate analysis terms optimization objective involving set affinity matrices formed comparing features within different layer solving optimization problem using gradient descent allows technique scale single images datasetlevel analysis including latter intra interimage relationships analyzing pretrained generative transformer provides insight computational strategy learned models equating affinity keyquery similarity across attention layers yields eigenvectors encoding scene spatial layout whereas defining affinity value vector similarity yields eigenvectors encoding object identity result suggests key query vectors coordinate attentional information flow according spatial proximity pathway value vectors refine semantic category representation pathway'\n",
      "Label(s): ['cs.CV']\n",
      " \n",
      "112623\n",
      "(256, 112623) (256, 58)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df.reset_index(inplace = True)\n",
    "train_df['Categories'] = train_df['Categories'].str.split(',Â ' , expand = True)\n",
    "\n",
    "\n",
    "test_df  = pd.read_csv('/kaggle/input/kriti2024/test.csv')\n",
    "\n",
    "#drop off the categories with 1 occurence\n",
    "train_df_filtered = train_df.groupby(\"Categories\").filter(lambda x: len(x) > 1)\n",
    "\n",
    "\n",
    "train_df_filtered[\"Categories\"] = train_df_filtered[\"Categories\"].apply(\n",
    "    lambda x: literal_eval(x)\n",
    ")\n",
    "\n",
    "test_split = 0.2\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    train_df_filtered,\n",
    "    test_size=test_split,\n",
    "    stratify=train_df_filtered[\"Categories\"].values,\n",
    ")\n",
    "\n",
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")\n",
    "\n",
    "terms = tf.ragged.constant(train_df[\"Categories\"].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "\n",
    "def invert_multi_hot(encoded_labels):\n",
    "    \"\"\"Reverse a single multi-hot encoded label to a list of vocab terms.\"\"\"\n",
    "    hot_indices = np.where(encoded_labels > 0.4)[0]\n",
    "    terms = np.take(vocab, hot_indices, mode='clip')  # Use 'clip' mode to handle out-of-bounds indices\n",
    "    return terms.tolist()\n",
    "\n",
    "\n",
    "print(len(vocab))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe[\"Categories\"].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"CONTEXT\"].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)\n",
    "\n",
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    print(\" \")\n",
    "\n",
    "vocabulary = set()\n",
    "train_df[\"CONTEXT\"].str.lower().str.split().apply(vocabulary.update)\n",
    "# train_df[\"Abstract\"].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)\n",
    "\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
    ")\n",
    "\n",
    "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
    "# training set.\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "\n",
    "train_batch,label = next(iter(train_dataset))\n",
    "print(train_batch.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc5e17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:28:02.639273Z",
     "iopub.status.busy": "2024-02-09T21:28:02.637926Z",
     "iopub.status.idle": "2024-02-09T21:28:02.656039Z",
     "shell.execute_reply": "2024-02-09T21:28:02.654789Z"
    },
    "id": "n9rTOOmoVRri",
    "outputId": "663bdbe9-3136-432f-a929-0b39009e141c",
    "papermill": {
     "duration": 0.033905,
     "end_time": "2024-02-09T21:28:02.658704",
     "exception": false,
     "start_time": "2024-02-09T21:28:02.624799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Categories</th>\n",
       "      <th>CONTEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34122</th>\n",
       "      <td>34122</td>\n",
       "      <td>[math.LO]</td>\n",
       "      <td>strong measure zero subsets kappa  paper answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>21911</td>\n",
       "      <td>[math.NT]</td>\n",
       "      <td>moments rank elliptic curves fix elliptic curv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243</th>\n",
       "      <td>12243</td>\n",
       "      <td>[cs.LG]</td>\n",
       "      <td>costar improved temporal counterfactual estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9945</th>\n",
       "      <td>9945</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CL]</td>\n",
       "      <td>language control diffusion efficiently scaling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33766</th>\n",
       "      <td>33766</td>\n",
       "      <td>[math.CO, math.AC]</td>\n",
       "      <td>generic initial ideals exterior algebraic shif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>2780</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>dual cognitive architecture incorporating bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>14348</td>\n",
       "      <td>[stat.ME, math.ST, stat.CO, stat.TH]</td>\n",
       "      <td>bayesian estimation bivariate copula using jef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33834</th>\n",
       "      <td>33834</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>pde enhancing generalization via pde adaptive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42292</th>\n",
       "      <td>42292</td>\n",
       "      <td>[cs.CR]</td>\n",
       "      <td>centralized intermediation decentralized web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50971</th>\n",
       "      <td>50971</td>\n",
       "      <td>[math.ST, stat.TH]</td>\n",
       "      <td>quantile regression transformation models cond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40495 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                            Categories  \\\n",
       "34122  34122                             [math.LO]   \n",
       "21911  21911                             [math.NT]   \n",
       "12243  12243                               [cs.LG]   \n",
       "9945    9945                 [cs.LG, cs.AI, cs.CL]   \n",
       "33766  33766                    [math.CO, math.AC]   \n",
       "...      ...                                   ...   \n",
       "2780    2780                 [cs.CV, cs.AI, cs.LG]   \n",
       "14348  14348  [stat.ME, math.ST, stat.CO, stat.TH]   \n",
       "33834  33834                        [cs.LG, cs.AI]   \n",
       "42292  42292                               [cs.CR]   \n",
       "50971  50971                    [math.ST, stat.TH]   \n",
       "\n",
       "                                                 CONTEXT  \n",
       "34122  strong measure zero subsets kappa  paper answe...  \n",
       "21911  moments rank elliptic curves fix elliptic curv...  \n",
       "12243  costar improved temporal counterfactual estima...  \n",
       "9945   language control diffusion efficiently scaling...  \n",
       "33766  generic initial ideals exterior algebraic shif...  \n",
       "...                                                  ...  \n",
       "2780   dual cognitive architecture incorporating bias...  \n",
       "14348  bayesian estimation bivariate copula using jef...  \n",
       "33834  pde enhancing generalization via pde adaptive ...  \n",
       "42292  centralized intermediation decentralized web e...  \n",
       "50971  quantile regression transformation models cond...  \n",
       "\n",
       "[40495 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5178ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:28:02.684127Z",
     "iopub.status.busy": "2024-02-09T21:28:02.683699Z",
     "iopub.status.idle": "2024-02-09T21:28:02.697726Z",
     "shell.execute_reply": "2024-02-09T21:28:02.696549Z"
    },
    "id": "CGiF7w1XyBdZ",
    "papermill": {
     "duration": 0.029813,
     "end_time": "2024-02-09T21:28:02.700166",
     "exception": false,
     "start_time": "2024-02-09T21:28:02.670353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54bd96f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T21:28:02.725590Z",
     "iopub.status.busy": "2024-02-09T21:28:02.725131Z",
     "iopub.status.idle": "2024-02-09T22:31:22.588896Z",
     "shell.execute_reply": "2024-02-09T22:31:22.587489Z"
    },
    "id": "K718Dr0H4O6a",
    "outputId": "b017213a-a20b-4a70-e4ac-9b2f83df1b71",
    "papermill": {
     "duration": 3800.120262,
     "end_time": "2024-02-09T22:31:22.832298",
     "exception": false,
     "start_time": "2024-02-09T21:28:02.712036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "159/159 [==============================] - 362s 2s/step - loss: 0.1344 - accuracy: 0.3103 - precision: 0.3573 - recall: 0.2786 - val_loss: 0.0934 - val_accuracy: 0.5247 - val_precision: 0.5906 - val_recall: 0.7096\n",
      "Epoch 2/10\n",
      "159/159 [==============================] - 348s 2s/step - loss: 0.0628 - accuracy: 0.5139 - precision: 0.7654 - recall: 0.5346 - val_loss: 0.0612 - val_accuracy: 0.5367 - val_precision: 0.6805 - val_recall: 0.7067\n",
      "Epoch 3/10\n",
      "159/159 [==============================] - 348s 2s/step - loss: 0.0449 - accuracy: 0.5879 - precision: 0.8260 - recall: 0.6728 - val_loss: 0.0542 - val_accuracy: 0.5620 - val_precision: 0.7132 - val_recall: 0.7213\n",
      "Epoch 4/10\n",
      "159/159 [==============================] - 358s 2s/step - loss: 0.0347 - accuracy: 0.6268 - precision: 0.8626 - recall: 0.7560 - val_loss: 0.0554 - val_accuracy: 0.5739 - val_precision: 0.7081 - val_recall: 0.7301\n",
      "Epoch 5/10\n",
      "159/159 [==============================] - 348s 2s/step - loss: 0.0283 - accuracy: 0.6500 - precision: 0.8864 - recall: 0.8059 - val_loss: 0.0582 - val_accuracy: 0.5642 - val_precision: 0.7204 - val_recall: 0.7268\n",
      "Epoch 6/10\n",
      "159/159 [==============================] - 359s 2s/step - loss: 0.0240 - accuracy: 0.6657 - precision: 0.9028 - recall: 0.8405 - val_loss: 0.0615 - val_accuracy: 0.5441 - val_precision: 0.6941 - val_recall: 0.7487\n",
      "Epoch 7/10\n",
      "159/159 [==============================] - 349s 2s/step - loss: 0.0208 - accuracy: 0.6685 - precision: 0.9161 - recall: 0.8637 - val_loss: 0.0658 - val_accuracy: 0.5697 - val_precision: 0.7448 - val_recall: 0.7061\n",
      "Epoch 8/10\n",
      "159/159 [==============================] - 358s 2s/step - loss: 0.0182 - accuracy: 0.6736 - precision: 0.9255 - recall: 0.8826 - val_loss: 0.0668 - val_accuracy: 0.5766 - val_precision: 0.7221 - val_recall: 0.7381\n",
      "Epoch 9/10\n",
      "159/159 [==============================] - 359s 2s/step - loss: 0.0166 - accuracy: 0.6775 - precision: 0.9331 - recall: 0.8951 - val_loss: 0.0685 - val_accuracy: 0.5739 - val_precision: 0.7243 - val_recall: 0.7373\n",
      "Epoch 10/10\n",
      "159/159 [==============================] - 350s 2s/step - loss: 0.0153 - accuracy: 0.6784 - precision: 0.9372 - recall: 0.9042 - val_loss: 0.0710 - val_accuracy: 0.5606 - val_precision: 0.7174 - val_recall: 0.7411\n",
      "CPU times: user 2h 37min 53s, sys: 57min 12s, total: 3h 35min 6s\n",
      "Wall time: 1h 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# import keras.optimizers\n",
    "initializer = tf.keras.initializers.HeUniform( seed = 223)\n",
    "initializer2 = tf.keras.initializers.HeNormal( seed = 123)\n",
    "final_initializer = tf.keras.initializers.GlorotUniform(seed = 425)\n",
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(1024, kernel_initializer = initializer,activation=\"swish\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.6),\n",
    "            layers.Dense(512,kernel_initializer = initializer,  activation=\"swish\"),\n",
    "            # layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256,kernel_initializer = initializer, activation=\"swish\"),\n",
    "            # layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(128, kernel_initializer = initializer2, activation=\"leaky_relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(),kernel_initializer = final_initializer, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    return shallow_mlp_model\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\",  Precision(), Recall()]\n",
    ")\n",
    "\n",
    "# shallow_mlp_model.compile(\n",
    "#     loss=HammingLoss(mode='multilabel'),\n",
    "#     optimizer=\"adam\",\n",
    "#     metrics=[\"accuracy\", \"binary_accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "# )\n",
    "history = shallow_mlp_model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2dc829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:31:23.163838Z",
     "iopub.status.busy": "2024-02-09T22:31:23.162768Z",
     "iopub.status.idle": "2024-02-09T22:31:43.703869Z",
     "shell.execute_reply": "2024-02-09T22:31:43.702750Z"
    },
    "id": "HnGs6CXz5grp",
    "outputId": "d7f3b4d6-b5da-4bd8-b824-8d6f07024756",
    "papermill": {
     "duration": 20.709942,
     "end_time": "2024-02-09T22:31:43.706269",
     "exception": false,
     "start_time": "2024-02-09T22:31:22.996327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 12s 566ms/step - loss: 0.0727 - accuracy: 0.5551 - precision: 0.7284 - recall: 0.7328\n",
      "  Test Loss: 0.0727\n",
      "Test binary accuracy: 0.5551\n",
      "Test Precision: 0.7284, Test Recall: 0.7328\n",
      "0.7305707205916312\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_bin_acc, test_precision, test_recall = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f'  Test Loss: {test_loss:.4f}')\n",
    "print(f\"Test binary accuracy: {test_bin_acc:.4f}\")\n",
    "print(f'Test Precision: {test_precision:.4f}, Test Recall: {test_recall:.4f}')\n",
    "f1 = (2 * test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6011581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:31:44.045523Z",
     "iopub.status.busy": "2024-02-09T22:31:44.044787Z",
     "iopub.status.idle": "2024-02-09T22:31:58.592018Z",
     "shell.execute_reply": "2024-02-09T22:31:58.590011Z"
    },
    "id": "EMOfRk7THLDo",
    "papermill": {
     "duration": 14.720977,
     "end_time": "2024-02-09T22:31:58.596110",
     "exception": false,
     "start_time": "2024-02-09T22:31:43.875133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/kriti2024/test.csv')\n",
    "\n",
    "def decontract(sentence):\n",
    "    # specific\n",
    "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
    "    sentence = re.sub(r\"can\\'t\", \"can not\", sentence)\n",
    "\n",
    "    # general\n",
    "    sentence = re.sub(r\"n\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" is\", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
    "    sentence = re.sub(r\"\\'t\", \" not\", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
    "    sentence = re.sub(r\"\\'m\", \" am\", sentence)\n",
    "    return sentence\n",
    "\n",
    "def cleanPunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', '', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\"\", sentence)\n",
    "\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stopwords) + \")\\\\W\", re.I)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "test_df['CONTEXT'] = test_df['Title'] + \". \" + test_df['Abstract']\n",
    "test_df.drop(labels=['Title', 'Abstract'], axis=1, inplace=True)\n",
    "\n",
    "test_df['CONTEXT']=test_df['CONTEXT'].str.lower()\n",
    "test_df['CONTEXT']=test_df['CONTEXT'].apply(decontract)\n",
    "test_df['CONTEXT']=test_df['CONTEXT'].apply(cleanPunc)\n",
    "test_df['CONTEXT']=test_df['CONTEXT'].apply(removeStopWords)\n",
    "test_df['CONTEXT']=test_df['CONTEXT'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad461321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:31:58.940285Z",
     "iopub.status.busy": "2024-02-09T22:31:58.939847Z",
     "iopub.status.idle": "2024-02-09T22:31:58.944839Z",
     "shell.execute_reply": "2024-02-09T22:31:58.943534Z"
    },
    "id": "ra3Ud-35q0dU",
    "outputId": "75ee5b43-05ec-43e0-b477-694e011512e3",
    "papermill": {
     "duration": 0.177049,
     "end_time": "2024-02-09T22:31:58.947251",
     "exception": false,
     "start_time": "2024-02-09T22:31:58.770202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df['CONTEXT']=test_df['CONTEXT'].apply(remove_top_words)\n",
    "# test_df['CONTEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2c3540c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:31:59.281909Z",
     "iopub.status.busy": "2024-02-09T22:31:59.281522Z",
     "iopub.status.idle": "2024-02-09T22:32:31.179501Z",
     "shell.execute_reply": "2024-02-09T22:32:31.178204Z"
    },
    "id": "Krm8gz8sGUkC",
    "outputId": "d682835a-457b-494d-933e-e1ea4f40fb73",
    "papermill": {
     "duration": 32.068057,
     "end_time": "2024-02-09T22:32:31.182170",
     "exception": false,
     "start_time": "2024-02-09T22:31:59.114113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 31s 711ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predicitions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Load the test dataset\n",
    "\n",
    "\n",
    "# Preprocess the test dataset\n",
    "test_df['Categories'] = np.nan  # Placeholder for predicted categories\n",
    "\n",
    "#text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "# Assuming train_df is your training dataframe with \"Abstract\" column\n",
    "#text_vectorizer.adapt(tf.data.Dataset.from_tensor_slices(test_df[\"Abstract\"].values).batch(batch_size))\n",
    "# train_df[\"Abstract\"].str.lower().str.split().apply(vocabulary.update)\n",
    "# train_df[\"Title\"].str.lower().str.split().apply(vocabulary.update)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_df[\"CONTEXT\"].values )\n",
    "test_dataset = test_dataset.map(lambda text: text_vectorizer(text)).batch(batch_size)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = shallow_mlp_model.predict(test_dataset)\n",
    "\n",
    "# Convert predicted binary labels to categories using list comprehension\n",
    "predicted_categories = [invert_multi_hot(row) for row in predictions]\n",
    "\n",
    "# Convert the list of lists to a numpy array\n",
    "predicted_categories = np.array(predicted_categories, dtype=object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af0b1377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:31.526582Z",
     "iopub.status.busy": "2024-02-09T22:32:31.525624Z",
     "iopub.status.idle": "2024-02-09T22:32:31.531786Z",
     "shell.execute_reply": "2024-02-09T22:32:31.530873Z"
    },
    "id": "SJQW8azh5AR_",
    "outputId": "37c81fa7-8dde-4805-d884-b627fbe1a4ee",
    "papermill": {
     "duration": 0.181517,
     "end_time": "2024-02-09T22:32:31.533966",
     "exception": false,
     "start_time": "2024-02-09T22:32:31.352449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10974,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11c67ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:31.886530Z",
     "iopub.status.busy": "2024-02-09T22:32:31.885789Z",
     "iopub.status.idle": "2024-02-09T22:32:31.894267Z",
     "shell.execute_reply": "2024-02-09T22:32:31.892940Z"
    },
    "id": "szFthszomHTd",
    "papermill": {
     "duration": 0.183132,
     "end_time": "2024-02-09T22:32:31.897205",
     "exception": false,
     "start_time": "2024-02-09T22:32:31.714073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "desired_column_order = [\n",
    "    'Id', 'math.AT', 'stat.AP', 'cs.AR', 'math.QA', 'q-bio.MN', 'eess.AS', 'eess.IV', 'stat.ME',\n",
    "    'econ.GN', 'eess.SP', 'q-fin.RM', 'cs.LG', 'cs.CR', 'q-bio.BM', 'q-fin.GN', 'q-fin.MF',\n",
    "    'q-fin.PR', 'math.CV', 'cs.LO', 'econ.TH', 'math.CO', 'cs.AI', 'math.AC', 'q-bio.CB',\n",
    "    'q-fin.CP', 'cs.CL', 'cs.DC', 'math.LO', 'math.NT', 'cs.SD', 'q-fin.TR', 'cs.CV',\n",
    "    'stat.ML', 'q-fin.EC', 'econ.EM', 'cs.CE', 'stat.CO', 'math.PR', 'q-bio.NC', 'math.AP',\n",
    "    'cs.OS', 'cs.NI', 'cs.IT', 'cs.PL', 'cs.GT', 'cs.DM', 'math.IT', 'cs.SE', 'cs.RO',\n",
    "    'stat.TH', 'cs.DB', 'math.ST', 'q-bio.GN', 'q-fin.PM', 'q-bio.TO', 'math.GR', 'cs.IR'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd41f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:32.251696Z",
     "iopub.status.busy": "2024-02-09T22:32:32.250968Z",
     "iopub.status.idle": "2024-02-09T22:32:32.255933Z",
     "shell.execute_reply": "2024-02-09T22:32:32.254999Z"
    },
    "id": "K6gG90AxlvEP",
    "papermill": {
     "duration": 0.178896,
     "end_time": "2024-02-09T22:32:32.258236",
     "exception": false,
     "start_time": "2024-02-09T22:32:32.079340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def extract_labels(sample):\n",
    "#     \"\"\"\n",
    "#     Extract labels from the sample string and return them as a set.\n",
    "\n",
    "#     Args:\n",
    "#     - sample (str): The sample string containing labels separated by commas.\n",
    "\n",
    "#     Returns:\n",
    "#     - label_set (set): A set containing the extracted labels.\n",
    "#     \"\"\"\n",
    "#     label_set = set(sample.split(','))\n",
    "#     return label_set\n",
    "\n",
    "\n",
    "# def multi_hot_encoding(labels, vocab):\n",
    "#     \"\"\"\n",
    "#     Perform multi-hot encoding on the extracted labels based on the given vocabulary.\n",
    "\n",
    "#     Args:\n",
    "#     - labels (set): A set containing the extracted labels.\n",
    "#     - vocab (set): The set of words in the vocabulary.\n",
    "\n",
    "#     Returns:\n",
    "#     - encoding (numpy array): The multi-hot encoding scheme for the labels.\n",
    "#     \"\"\"\n",
    "#     encoding = [1 if label in labels else 0 for label in vocab]\n",
    "#     return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd54c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:32.600582Z",
     "iopub.status.busy": "2024-02-09T22:32:32.599419Z",
     "iopub.status.idle": "2024-02-09T22:32:32.604383Z",
     "shell.execute_reply": "2024-02-09T22:32:32.603322Z"
    },
    "id": "K4e-mVbtmThH",
    "papermill": {
     "duration": 0.177767,
     "end_time": "2024-02-09T22:32:32.606695",
     "exception": false,
     "start_time": "2024-02-09T22:32:32.428928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_labels = pd.DataFrame(columns=desired_column_order)\n",
    "# encoded_labels[\"Id\"] = test_df[\"Id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f296cf28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:32.947637Z",
     "iopub.status.busy": "2024-02-09T22:32:32.947190Z",
     "iopub.status.idle": "2024-02-09T22:32:32.951117Z",
     "shell.execute_reply": "2024-02-09T22:32:32.950281Z"
    },
    "id": "C40NeXqRnSce",
    "papermill": {
     "duration": 0.178197,
     "end_time": "2024-02-09T22:32:32.953522",
     "exception": false,
     "start_time": "2024-02-09T22:32:32.775325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# predicted_categories = pd.DataFrame(predicted_categories)\n",
    "# predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b1f9ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:33.301149Z",
     "iopub.status.busy": "2024-02-09T22:32:33.300344Z",
     "iopub.status.idle": "2024-02-09T22:32:33.304809Z",
     "shell.execute_reply": "2024-02-09T22:32:33.303754Z"
    },
    "id": "AzCwa5hGmkGy",
    "papermill": {
     "duration": 0.180868,
     "end_time": "2024-02-09T22:32:33.307036",
     "exception": false,
     "start_time": "2024-02-09T22:32:33.126168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for category in encoded_labels.columns[1:]:\n",
    "#     # Check if each category is present in the 'Categories' column\n",
    "#     encoded_labels[category] = predicted_categories.apply(lambda x: 1 if category in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8eb3765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:33.649550Z",
     "iopub.status.busy": "2024-02-09T22:32:33.648773Z",
     "iopub.status.idle": "2024-02-09T22:32:33.652929Z",
     "shell.execute_reply": "2024-02-09T22:32:33.652059Z"
    },
    "id": "TTVJflm9mpWS",
    "papermill": {
     "duration": 0.178266,
     "end_time": "2024-02-09T22:32:33.655190",
     "exception": false,
     "start_time": "2024-02-09T22:32:33.476924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a051274b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:33.999500Z",
     "iopub.status.busy": "2024-02-09T22:32:33.998745Z",
     "iopub.status.idle": "2024-02-09T22:32:34.004688Z",
     "shell.execute_reply": "2024-02-09T22:32:34.003837Z"
    },
    "id": "7rfbjs2SnZnu",
    "outputId": "46393440-c1f4-4d30-f3e4-f80981ac0ce9",
    "papermill": {
     "duration": 0.181365,
     "end_time": "2024-02-09T22:32:34.006805",
     "exception": false,
     "start_time": "2024-02-09T22:32:33.825440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cs.LG', 'cs.CV', 'eess.IV']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_categories[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36928f",
   "metadata": {
    "id": "nBoDvgz1_NgT",
    "outputId": "a4752752-1c1b-49e2-b778-dda5d60ab281",
    "papermill": {
     "duration": 0.169181,
     "end_time": "2024-02-09T22:32:34.348263",
     "exception": false,
     "start_time": "2024-02-09T22:32:34.179082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b6643a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:34.691295Z",
     "iopub.status.busy": "2024-02-09T22:32:34.690130Z",
     "iopub.status.idle": "2024-02-09T22:32:34.975200Z",
     "shell.execute_reply": "2024-02-09T22:32:34.973931Z"
    },
    "id": "x6rLOJnbKGBA",
    "papermill": {
     "duration": 0.458767,
     "end_time": "2024-02-09T22:32:34.978115",
     "exception": false,
     "start_time": "2024-02-09T22:32:34.519348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create a MultiLabelBinarizer and fit on unique categories\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(predicted_categories)\n",
    "\n",
    "# Transform the predicted_categories into binary representation\n",
    "predicted_binary = mlb.transform(predicted_categories)\n",
    "\n",
    "# Create the predicted_df DataFrame\n",
    "predicted_df = pd.DataFrame(predicted_binary, columns=mlb.classes_, index=test_df.index)\n",
    "\n",
    "\n",
    "# Concatenate the original test_df with the predicted_df\n",
    "result_df = pd.concat([test_df, predicted_df], axis=1)\n",
    "\n",
    "# Drop the 'Title' and 'Abstract' columns\n",
    "result_df = result_df.drop(['CONTEXT','Categories'], axis=1)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "result_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71538cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:35.325296Z",
     "iopub.status.busy": "2024-02-09T22:32:35.324847Z",
     "iopub.status.idle": "2024-02-09T22:32:35.330201Z",
     "shell.execute_reply": "2024-02-09T22:32:35.329092Z"
    },
    "id": "Xw_XTDbn4fMR",
    "papermill": {
     "duration": 0.182352,
     "end_time": "2024-02-09T22:32:35.332396",
     "exception": false,
     "start_time": "2024-02-09T22:32:35.150044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SimpleMultiLabelBinarizer:\n",
    "#     def __init__(self):\n",
    "#         self.classes_ = []\n",
    "\n",
    "#     def fit(self, Y):\n",
    "#         \"\"\"Fit the binarizer to the unique categories in Y\"\"\"\n",
    "#         unique_classes = set(cls for sublist in Y for cls in sublist)\n",
    "#         self.classes_ = sorted(list(unique_classes))\n",
    "\n",
    "#     def transform(self, Y):\n",
    "#         \"\"\"Transform the categories in Y to a binary matrix\"\"\"\n",
    "#         binary_matrix = []\n",
    "#         for labels in Y:\n",
    "#             row = [int(cls in labels) for cls in self.classes_]\n",
    "#             binary_matrix.append(row)\n",
    "#         return binary_matrix\n",
    "\n",
    "#     def fit_transform(self, Y):\n",
    "#         \"\"\"Fit to the data, then transform it\"\"\"\n",
    "#         self.fit(Y)\n",
    "#         return self.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "191324ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:35.776920Z",
     "iopub.status.busy": "2024-02-09T22:32:35.776101Z",
     "iopub.status.idle": "2024-02-09T22:32:35.783291Z",
     "shell.execute_reply": "2024-02-09T22:32:35.782296Z"
    },
    "id": "tcYWpzqcIncP",
    "papermill": {
     "duration": 0.280212,
     "end_time": "2024-02-09T22:32:35.785648",
     "exception": false,
     "start_time": "2024-02-09T22:32:35.505436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['q-fin.PR', 'q-fin.MF', 'q-fin.CP']), list(['cs.AR']),\n",
       "       list(['cs.LG', 'cs.CV', 'eess.IV']), ..., list(['cs.CV']),\n",
       "       list(['cs.LG', 'cs.AI', 'cs.CV', 'cs.RO']), list(['cs.LO'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62a9ba66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:36.153820Z",
     "iopub.status.busy": "2024-02-09T22:32:36.152882Z",
     "iopub.status.idle": "2024-02-09T22:32:36.456066Z",
     "shell.execute_reply": "2024-02-09T22:32:36.454820Z"
    },
    "id": "XwWXqKzaIsg7",
    "papermill": {
     "duration": 0.48353,
     "end_time": "2024-02-09T22:32:36.459455",
     "exception": false,
     "start_time": "2024-02-09T22:32:35.975925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predicted_df = pd.read_csv('submission.csv')\n",
    "\n",
    "desired_column_order = [\n",
    "    'Id', 'math.AT', 'stat.AP', 'cs.AR', 'math.QA', 'q-bio.MN', 'eess.AS', 'eess.IV', 'stat.ME',\n",
    "    'econ.GN', 'eess.SP', 'q-fin.RM', 'cs.LG', 'cs.CR', 'q-bio.BM', 'q-fin.GN', 'q-fin.MF',\n",
    "    'q-fin.PR', 'math.CV', 'cs.LO', 'econ.TH', 'math.CO', 'cs.AI', 'math.AC', 'q-bio.CB',\n",
    "    'q-fin.CP', 'cs.CL', 'cs.DC', 'math.LO', 'math.NT', 'cs.SD', 'q-fin.TR', 'cs.CV',\n",
    "    'stat.ML', 'q-fin.EC', 'econ.EM', 'cs.CE', 'stat.CO', 'math.PR', 'q-bio.NC', 'math.AP',\n",
    "    'cs.OS', 'cs.NI', 'cs.IT', 'cs.PL', 'cs.GT', 'cs.DM', 'math.IT', 'cs.SE', 'cs.RO',\n",
    "    'stat.TH', 'cs.DB', 'math.ST', 'q-bio.GN', 'q-fin.PM', 'q-bio.TO', 'math.GR', 'cs.IR'\n",
    "]\n",
    "\n",
    "# Reorder columns based on the desired order\n",
    "predicted_df = predicted_df[desired_column_order]\n",
    "\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "predicted_df.to_csv('lohit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f9cbbfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:36.812556Z",
     "iopub.status.busy": "2024-02-09T22:32:36.812092Z",
     "iopub.status.idle": "2024-02-09T22:32:36.818805Z",
     "shell.execute_reply": "2024-02-09T22:32:36.817894Z"
    },
    "id": "kqkjFh8cXldf",
    "papermill": {
     "duration": 0.184543,
     "end_time": "2024-02-09T22:32:36.820852",
     "exception": false,
     "start_time": "2024-02-09T22:32:36.636309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desired_column_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53575c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-09T22:32:37.169573Z",
     "iopub.status.busy": "2024-02-09T22:32:37.168386Z",
     "iopub.status.idle": "2024-02-09T22:32:38.707405Z",
     "shell.execute_reply": "2024-02-09T22:32:38.705780Z"
    },
    "id": "mvWudHfZpEXi",
    "papermill": {
     "duration": 1.715202,
     "end_time": "2024-02-09T22:32:38.709500",
     "exception": true,
     "start_time": "2024-02-09T22:32:36.994298",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'submissions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubmissions.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'submissions.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"submissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d072c",
   "metadata": {
    "id": "pJ3IIsxapHX2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c64adf",
   "metadata": {
    "id": "ByuECzSlJlRX",
    "outputId": "07e428cf-ee34-41d9-c728-e914ae3bc9c8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV files\n",
    "df1 = pd.read_csv('/content/submission1.csv')\n",
    "df2 = pd.read_csv('/content/submissions (11).csv')\n",
    "\n",
    "# Ensure the column names match\n",
    "if list(df1.columns) == list(df2.columns):\n",
    "    # Compare the DataFrames\n",
    "    concatenated = pd.concat([df1, df2]).drop_duplicates(keep=False)\n",
    "    #differences = df1.compare(df2)\n",
    "\n",
    "    num_differences = len(concatenated) / 2  # Divide by 2 because each difference appears twice in the concatenation\n",
    "    print(f\"Number of different elements (rows): {int(num_differences)}\")\n",
    "else:\n",
    "    print(\"The column namesÂ doÂ notÂ match.\")\n",
    "\n",
    "#     # Check if there are any differences\n",
    "#     if not differences.empty:\n",
    "#         print(\"Differences found:\")\n",
    "#         print(differences)\n",
    "#     else:\n",
    "#         print(\"The files are identical in terms of data.\")\n",
    "# else:\n",
    "#     print(\"The column namesÂ doÂ notÂ match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4b805",
   "metadata": {
    "id": "P1-E1r7UKm-U",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4414200,
     "sourceId": 7582942,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3992.94275,
   "end_time": "2024-02-09T22:32:41.993922",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-09T21:26:09.051172",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
